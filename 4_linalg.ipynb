{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Linear algebra operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operations\n",
    "\n",
    "Linear algebra is a branch of mathematics dealing with vector spaces. Linear algebra operations such as transposes, dot products, matrix multiplications and others are often very useful when manipulating numeric datasets. Using these operations often allows us to avoid writing explicit loops, and thus make our code more readable, more concise and faster to execute.\n",
    "\n",
    "In the following steps we'll implement linear regression using `numpy` linear algebra operations. We will start with the functional form of the regression: how the predicted target values depend on the regression coefficients the of features (aka predictors or regressors). \n",
    "\n",
    "Once we have the coefficients $\\mathrm{\\beta}$ and the matrix with the predictors $\\mathrm{X}$ we can calculate predicted targets $\\mathrm{\\hat{y}}$ according to:\n",
    "\n",
    "$$\n",
    "\\mathrm{\\hat{y}} = \\beta_0 + \\mathrm{X}\\mathrm{\\beta}\n",
    "$$\n",
    "\n",
    "If we add an extra column with all $1$s to the matrix $\\mathrm{X}$, we can write this without the intercept $\\beta_0$:\n",
    "\n",
    "$$\n",
    "\\mathrm{\\hat{y}} = \\mathrm{X}\\mathrm{\\beta}\n",
    "$$\n",
    "\n",
    "This operation is the matrix multiplication. In this case the first matrix is $N\\times M$ where N is the number datapoints (rows) and $M$ the number of predictors (including the extra row of ones). The second matrix is $M\\times 1$, so it is a column vector.\n",
    "\n",
    "In this particular case, for each row of M we multiply it with $\\beta$ and the sum these multiplications is our predicted $\\hat{y}$ for each row. This can be written explicitly as:\n",
    "\n",
    "$$\n",
    "\\mathrm{\\hat{y}_i} = \\sum_{m=1}^M X_{i,m} \\beta_m\n",
    "$$\n",
    "\n",
    "We can see that the matrix multiplication version is much more concise. The same is true in numpy code: it's more concise to implement this using the matrix multiplication function `numpy.dot` than write a bunch of loops.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication / dot product\n",
    "\n",
    "In numpy the concept of dot product (aka scalar product) is treated as\n",
    "a special case of matrix multiplication. The numpy function `dot` for simple dot product between vectors, for multiplying a matrix by a vector, as well as for multyplying two matrices.\n",
    "\n",
    "The definition of dot product between two vectors $u$ and $v$ is:\n",
    "\n",
    "$$\\langle u, v\\rangle = \\sum_{i=1}^N u_i v_i$$\n",
    "\n",
    "Other notations that you will come across for this operation are:\n",
    "$u \\cdot v$, $u^T v$.\n",
    "\n",
    "In numpy we write\n",
    "```python\n",
    "numpy.dot(u, v)\n",
    "```\n",
    "or\n",
    "```python\n",
    "u.dot(v)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.1\n",
    "\n",
    "Create two vectors of random values between -10 and 10 of size 100. Compute:\n",
    "- elementwise product between them\n",
    "- dot (scalar) product between them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When multiplying two matrices, the number of columns in the first one needs to be equal to the number of rows in the second one. For matrices $A_{m\\times n}$ and $B_{n \\times p}$, the resulting matrix will be $C_{m \\times p}$. It is defined as:\n",
    "\n",
    "$$\n",
    "C_{i,j} = \\sum_{k=1}^n A_{i,k}B_{k,j}\n",
    "$$\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/Matrix_multiplication_diagram_2.svg/470px-Matrix_multiplication_diagram_2.svg.png)\n",
    "\n",
    "In `numpy` we simply use `dot`:\n",
    "\n",
    "```python\n",
    "numpy.dot(A, B)\n",
    "```\n",
    "or\n",
    "\n",
    "```python\n",
    "A.dot(B)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2\n",
    "\n",
    "- Create a random matrix $A_{3\\times 4}$ and another random matrix $B_{4 \\times 2}$. Multiply AB.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a random matrix $C_{3\\times 3}$ and $D_{3\\times3}$. Multiply CD. Multiply DC. Is matrix multiplication commutative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a identity matrix $I_{3\\times 3}$.  Multiply IC, CI, DI, ID. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What will be the result of multiplying a matrix $Z_{m\\times n}$ by a matrix $O_{n \\times p}$ whose all entries are zero? Check your answer using some examples in `numpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 4.3\n",
    "\n",
    "- Create a random matrix $A_{3\\times 4}$ and another random matrix $B_{2 \\times 4}$. Can you transform one of them so that they can be multiplied? Try this in `numpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose\n",
    "\n",
    "We have already encountered matrix transpose. The mathematical notation for the transpose of matrix $A$ is $A^T$. Transposing a matrix simply means making the rows into columns and columns into rows. If $A$ is $m \\times n$ then $A^T$ is $n \\times m$. The values are:\n",
    "\n",
    "$$A^T_{i,j} = A_{j,i}$$\n",
    "\n",
    "In `numpy` the transpose is simply written `A.T`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.4\n",
    "\n",
    "- Create a random $4 \\times 5$ matrix and verify that the above equality holds for it.\n",
    "- What would be the outcome of $(A^T)^T$? Check this in `numpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse\n",
    "\n",
    "For scalar numbers the multiplicative inverse (aka reciprocal) of number $n$ is $\\frac{1}{n}$, also written as $n^{-1}$. This inverse has certain properties, like:\n",
    "- $n^{-1}n = 1$\n",
    "- $(n^{-1})^{-1} = n$\n",
    "\n",
    "There is an analogous concept for matrices. For a square matrix $A_{m \\times m}$, its inverse is written $A^{-1}$ and it satisfies:\n",
    "\n",
    "- $A^{-1}A = I$ where $I$ is the $m \\times m$ identity matrix\n",
    "- $(A^{-1})^{-1} = A$\n",
    "- $(A^T)^{-1} = (A^{-1})^T$\n",
    "\n",
    "Not all matrices are invertible: a matrix needs to be square, and its [determinant](https://en.wikipedia.org/wiki/Determinant) needs to be non-zero. There is a function to invert matrices in `scipy.linalg` called `inv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.28220008  0.13801978  0.15833848]\n",
      " [ 0.45325715  0.17665677  0.47649004]\n",
      " [ 0.88278238  0.55563422  0.22141151]]\n",
      "[[ 52.63763471 -13.39479568  -8.81650803]\n",
      " [-74.71544028  18.03171689  14.62614014]\n",
      " [-22.37065785   8.15517988   2.96404637]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import inv\n",
    "A = numpy.random.uniform(0,1,(3,3))\n",
    "print(A)\n",
    "print(inv(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $A^{-1}A = I$ where $I$ is the $m \\times m$ identity matrix\n",
    "- $(A^{-1})^{-1} = A$\n",
    "- $(A^T)^{-1} = (A^{-1})^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.5\n",
    "\n",
    "Verify the three properties of the matrix inverse operations listed above for a random $m \\times m$ numpy matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Least Squares formula for Linear Regression\n",
    "\n",
    "We are now ready to implement the formula which can be used to find the coefficients of linear regression:\n",
    "\n",
    "$$\\hat\\beta = (X^TX)^{-1}X^Ty$$\n",
    "\n",
    "Remember that $X$ has $N$ rows corresponding to the $N$ datapoints, and $M$ columns corresponding to the $M$ predictors. The formula defines the vector $\\hat\\beta$ with the $M$ regression coefficients.\n",
    "\n",
    "We will apply this formula to the winequality dataset.\n",
    "\n",
    "Previously we loaded this dataset into a structured array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599,)\n"
     ]
    }
   ],
   "source": [
    "# Load winequality as a structured array\n",
    "data = numpy.genfromtxt(\"winequality-red.csv\", names=True, delimiter=';')\n",
    "# Convert the array into a matrix. We'll have the target in the last column\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12)\n"
     ]
    }
   ],
   "source": [
    "# Convert structured array into array of numeric values\n",
    "Xy = data.view((data.dtype[0], len(data.dtype)))\n",
    "print(Xy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 11)\n",
      "(1599, 1)\n"
     ]
    }
   ],
   "source": [
    "# Extract X and y from Xy\n",
    "X = Xy[:,:-1]\n",
    "y = Xy[:,-1:]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.      7.4     0.7   ...,   3.51    0.56    9.4  ]\n",
      " [  1.      7.8     0.88  ...,   3.2     0.68    9.8  ]\n",
      " [  1.      7.8     0.76  ...,   3.26    0.65    9.8  ]\n",
      " ..., \n",
      " [  1.      6.3     0.51  ...,   3.42    0.75   11.   ]\n",
      " [  1.      5.9     0.645 ...,   3.57    0.71   10.2  ]\n",
      " [  1.      6.      0.31  ...,   3.39    0.66   11.   ]]\n"
     ]
    }
   ],
   "source": [
    "X_new = numpy.hstack([ numpy.ones((1599,1)), X ])\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.6\n",
    "\n",
    "Implement function `fit` which takes a matrix of predictors and a vector of targets, and returns the vector of regression coefficients computed according to the OLS formula.\n",
    "Apply this function to the winequality data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$(X^T X)^{-1} X^T y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y):\n",
    "    # ----------------------------------\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.7\n",
    "\n",
    "Implement function `predict` which takes a vector of coefficients and a vector of predictors, and returns the predicted targets according to the regression formula (see beginning of notebook). Apply this function to the coefficients from the previous exercise, and the winequality data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(beta, X):\n",
    "    #--------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.8\n",
    "\n",
    "Define the following two functions to quantify how well the regression is able to predict the targets:\n",
    "- `mse` - mean squared error, defined as the mean of the squared difference between each prediction and true target: $$MSE(y, \\hat{y}) = \\frac{1}{N}\\sum_{i=1}^N (y_i-\\hat{y}_i)^2$$\n",
    "- `mae` - mean absolute error, defined as the mean of the absolute difference between each prediction and true target: $$MAE(y, \\hat{y}) = \\frac{1}{N}\\sum_{i=1}^N abs(y_i-\\hat{y}_i)$$\n",
    "\n",
    "Check how well your regression functions predict the targets in winequality according to these error measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.9\n",
    "\n",
    "- Load the iris data and extract the first three column into a predictor matrix, and the fourth column into a target vector. Apply the functions `fit` and `predict` to this data, and check the MSE and MAE of your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
