{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Distance and similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance metrics\n",
    "\n",
    "The distance metric represents the distance between two points $x$ and $y$. A point in $n$-dimensional space can be represented by a vector of length $n$. \n",
    "\n",
    "\n",
    "### Applications\n",
    "\n",
    "Some examples of applications of distance metrics:\n",
    "- k-nearest neighbors algorithm: to calculate the k points that are closest to the new unlabelled point.\n",
    "- Clustering algorithms: to calculate the distance between records inside the cluster and to calculate the distance between different clusters. For example, k-means clustering.\n",
    "\n",
    "\n",
    "Some frequently used distance metrics include:\n",
    "- Euclidean distance: $$D_{euc}(x, y) = \\left(\\sum_{i=1}^{n}(x_{i}-y_{i})^2\\right)^{0.5}$$\n",
    "- Manhattan distance: $$D_{manh}(x, y) = \\sum_{i=1}^{n} abs(x_{i}-y_{i})$$\n",
    "\n",
    "In general, distance metrics satisfy some properties such as:\n",
    "- The distance between two points is non-negative. \n",
    "- The distance from a point to the point itself is equal to 0. \n",
    "- The distance from point $i$ to point $j$ is exactly equal to the distance from point $j$ to point $i$ (symmetry). \n",
    "- The distance from point $i$ to point $j$ via point $k$ is always longer or equal than the direct distance from $i$ to $j$ (triangle inequality). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan distance:  2\n"
     ]
    }
   ],
   "source": [
    "# function to calculate manhattan distance between two points x and y\n",
    "def manhattan_distance(x, y):\n",
    "    return numpy.sum(numpy.abs(x-y))\n",
    "        \n",
    "x = numpy.array([1,3])\n",
    "y = numpy.array([2,4])\n",
    "print(\"Manhattan distance: \", manhattan_distance(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1\n",
    "\n",
    "Create a function to calculate the Euclidean distance between two points x and y. \n",
    "Do not use explicit loops.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "a = numpy.array([0.0, 0.0])\n",
    "b = numpy.array([1.0, 1.0])\n",
    "c = numpy.array([2.0, 2.0])\n",
    "print(euclidean(a, b))\n",
    "print(euclidean(a, c))\n",
    "```\n",
    "Output:\n",
    "```\n",
    "1.41421356237\n",
    "2.82842712475\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41421356237\n",
      "2.82842712475\n"
     ]
    }
   ],
   "source": [
    "# ....................................................\n",
    "def euclidean(a, b):\n",
    "    return ((a-b)**2).sum()**0.5\n",
    "\n",
    "a = numpy.array([0.0, 0.0])\n",
    "b = numpy.array([1.0, 1.0])\n",
    "c = numpy.array([2.0, 2.0])\n",
    "print(euclidean(a, b))\n",
    "print(euclidean(a, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.2\n",
    "\n",
    "Load the iris data into a 150x4 numpy array. Compute the Euclidean distance between the first row and each other row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "0.1\n",
      "16\n",
      "[ 5.1  3.5  1.4  0.2]\n",
      "[ 5.1  3.5  1.4  0.3]\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "# .........................\n",
    "iris = numpy.genfromtxt(\"iris.txt\")\n",
    "data = iris[:,0:4].astype('float')\n",
    "print(data.shape)\n",
    "distances = numpy.array([ euclidean(data[0], data[i]) for i in range(data.shape[0])])\n",
    "print(distances[1:].min())\n",
    "print(distances[1:].argmin())\n",
    "print(data[0])\n",
    "print(data[17])\n",
    "print(euclidean(data[0], data[17]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity metrics\n",
    "\n",
    "A similarity metric quantifies how similar two objects are. \n",
    "\n",
    "One often used similarity metric for vectors is the cosine similarity.\n",
    "When the cosine is equal to 1 the vectors point in the same direction, and when the cosine is equal to -1 then the vectors are the opposite of each other.\n",
    "\n",
    "Cosine similarity: $$cosine(x, y) = \\frac{x^Ty}{||x||\\cdot ||y||} = \\frac{\\sum_{i=1}^n x_i y_i}{\\left(\\sum_{i=1}^n x_{i}^2\\right)^{0.5} \\left(\\sum_{i=1}^n y_{i}^2\\right)^{0.5}}$$\n",
    "\n",
    "The cosine similarity between $x$ and $y$ is the dot product between $x$ and $y$ divided by the product of the L2-norms of $x$ and $y$.\n",
    "\n",
    "In text-mining the cosine similarity can be used to represent the similarity between two documents. We can represent documents as vectors of word counts or similar weights.\n",
    "\n",
    "High cosine similarity between two such vectors can be interpreted as these two documents sharing many words in common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.3\n",
    "Create a function that calculates the cosine similarity between two vectors. Do not use for-loops.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "a = numpy.array([0.0, 1.0])\n",
    "b = numpy.array([1.0, 0.0])\n",
    "c = numpy.array([0.0, -1.0])\n",
    "print(cosine(a, b))\n",
    "print(cosine(a, a))\n",
    "print(cosine(a, c))\n",
    "```\n",
    "Output:\n",
    "```\n",
    "0.0\n",
    "1.0\n",
    "-1.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "-1.0\n",
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "# ...........................................\n",
    "def cosine1(a, b):\n",
    "    return a.dot(b) / (a.dot(a)**0.5 * b.dot(b)**0.5)\n",
    "def cosine2(a, b):\n",
    "    return (a*b).sum()/((a**2).sum()**0.5 * (b**2).sum()**0.5)\n",
    "a = numpy.array([0.0, 1.0])\n",
    "b = numpy.array([1.0, 0.0])\n",
    "c = numpy.array([0.0, -1.0])\n",
    "print(cosine1(a, b))\n",
    "print(cosine2(a, b))\n",
    "print(cosine1(a, a))\n",
    "print(cosine2(a, a))\n",
    "print(cosine1(a, c))\n",
    "print(cosine2(a, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance measures for comparing strings\n",
    "\n",
    "Distance measures for comparing strings with each other:\n",
    "- Hamming distance: number of positions at which two strings of the same length differ.\n",
    "    $$D_{hamming}(x, y) =  \\sum_{i=1}^{n} x_{i} \\neq y_{i} $$\n",
    "- Levenshtein distance: the minimum number of operations required to transform one string into another string. The operations are insertion, deletion and substitutions and each operations has a cost (often unit costs are used). The Levenshtein distance is commonly used when similarity between two words needs to be measured. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.3\n",
    "Create a function to calculate the Hamming distance between two strings. The strings need to have the same length.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "a = 'Panama'\n",
    "b = 'Pamela'\n",
    "hamming(a, b)\n",
    "```\n",
    "Output:\n",
    "```\n",
    "3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-40e1568f1713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Pamela'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#print(hamming1(a, b)        )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhamming2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-40e1568f1713>\u001b[0m in \u001b[0;36mhamming2\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Panamaxxx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    }
   ],
   "source": [
    "# .....................................\n",
    "def hamming1(a, b):\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError(\"Unqual string lengths\")\n",
    "    return sum((a[i] != b[i] for i in range(len(a))))\n",
    "def hamming2(a, b):\n",
    "    a = numpy.array(list(a))\n",
    "    b = numpy.array(list(b))\n",
    "    return (a != b).sum()\n",
    "               \n",
    "a = 'Panamaxxx'\n",
    "b = 'Pamela'\n",
    "#print(hamming1(a, b)        )\n",
    "print(hamming2(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance metrics in scikit-learn\n",
    "\n",
    "Scikit-learn is a library for machine learning algorithms in Python. Scikit-learn includes functions for classification, regression, clustering, dimensionality reduction, model selection and preprocessing. \n",
    "For more information:  http://scikit-learn.org/stable/\n",
    "\n",
    "The class to calculate distances is in the module ``neighbors`` of the scikit-learn library.\n",
    "One can access the class via: ``sklearn.neighbors.DistanceMetric``\n",
    "\n",
    "The ``DistanceMetric`` class includes different distance metrics, such as Euclidean and Manhattan, Chebyshev, Minkowski, Mahalanobis, Hamming etc.\n",
    "\n",
    "For more information about the distance metrics that are included in the ``DistanceMetric`` class:  http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html\n",
    "\n",
    "The most important methods of the ``DistanceMetric`` class are the ``get_metric`` and the ``pairwise`` functions. \n",
    "\n",
    "The ``get_metric`` function is used to specify which metric is used, for example 'euclidean' or 'manhattan'. \n",
    "The ``pairwise`` function is used to calculate the pairwise distances between points in an array x. \n",
    "\n",
    "See the examples below.\n",
    "\n",
    "There is also a simple function to calculate pairwise distances according to a number of metrics:\n",
    "```python\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance:\n",
      "[[ 0.          1.41421356  3.        ]\n",
      " [ 1.41421356  0.          2.23606798]\n",
      " [ 3.          2.23606798  0.        ]]\n",
      "[[ 0.          1.41421356  3.        ]\n",
      " [ 1.41421356  0.          2.23606798]\n",
      " [ 3.          2.23606798  0.        ]]\n",
      "Manhattan distance:\n",
      "[[ 0.  2.  3.]\n",
      " [ 2.  0.  3.]\n",
      " [ 3.  3.  0.]]\n",
      "[[ 0.  2.  3.]\n",
      " [ 2.  0.  3.]\n",
      " [ 3.  3.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.neighbors\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# we want to calculate the pairwise distance between three points in a 2D space\n",
    "x = numpy.array([[1,3], [2, 4], [1, 6]])\n",
    "\n",
    "# Euclidean distance\n",
    "d1 = sklearn.neighbors.DistanceMetric.get_metric('euclidean')\n",
    "print(\"Euclidean distance:\")\n",
    "print(d1.pairwise(x))\n",
    "print(pairwise_distances(x, metric='euclidean'))\n",
    "# Manhattan distance\n",
    "d2 = sklearn.neighbors.DistanceMetric.get_metric('manhattan')\n",
    "print(\"Manhattan distance:\")\n",
    "print(d2.pairwise(x))\n",
    "print(pairwise_distances(x, metric='manhattan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity in scipy and scikit-learn\n",
    "\n",
    "Cosine similarity is implemented in both scipy and in scikit-learn.\n",
    "\n",
    "In scipy:\n",
    "`scipy.spatial.distance.cosine(x,y)` calculates the cosine distance between two points `x` and `y` where `x` and `y` are both represented by a vector.\n",
    "\n",
    "Note that in order to convert the distance to similarity, you should subtract distance from 1.\n",
    "\n",
    "In scikit-learn:\n",
    "`sklearn.metrics.pairwise.cosine_similarity(x)` calculates the pairwise cosine similarities between all rows in array `x`.\n",
    "\n",
    "\n",
    "**IMPORTANT** Verify, and remember, which of these implementations work with sparse matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity in scipy \n",
    "\n",
    "import scipy.spatial.distance\n",
    "x = [1, 0, -1]\n",
    "y = [-1,-1, 0]\n",
    "print(1 - scipy.spatial.distance.cosine(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-0.5  1. ]]\n"
     ]
    }
   ],
   "source": [
    "# pairwise cosine similarity in sklearn\n",
    "import sklearn.metrics.pairwise\n",
    "x = numpy.array([[1, 0, -1], [-1,-1, 0]])\n",
    "print(sklearn.metrics.pairwise.cosine_similarity(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.4 \n",
    "\n",
    "Use the function `word_count` which you implemented in notebook [5_sparse.ipynb](5_sparse.ipynb) to create a document-term matrix from the first 100 rows of file [coco_val.txt](coco_val.txt). \n",
    "- Does your cosine function work on rows of the sparse document-term matrix? If not, do you know why not?\n",
    "- Compute the pairwise cosine similarity between the rows of your document-term matrix using the `sklearn` implementation. Which document is the most similar to the first row according to cosine similarity?  \n",
    "- Based on the above experiment, suggest ways of modifying the word counts to make the cosine similarity more useful as a metric of text similarity. Implement your idea and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar sentence to texts[0] according to cosine similarity\n",
      "['a', 'child', 'holding', 'a', 'flowered', 'umbrella', 'and', 'petting', 'a', 'yak']\n",
      "['a', 'woman', 'on', 'a', 'motorcycle', 'wearing', 'a', 'bag', 'and', 'passing', 'a', 'car']\n",
      "\n",
      "Most similar sentence to texts[0] according to cosine similarity (remove stopwords)\n",
      "['child', 'holding', 'flowered', 'umbrella', 'petting', 'yak']\n",
      "['boy', 'holding', 'an', 'umbrella', 'while', 'standing', 'next', 'to', 'livestock']\n"
     ]
    }
   ],
   "source": [
    "from wc import word_count\n",
    "texts = [ line.split()  for line in open(\"coco_val.txt\")][:100]\n",
    "vocab, M = word_count(texts)\n",
    "\n",
    "# Does your cosine function work on rows of the sparse document-term matrix? If not, do you know why not?\n",
    "# print(cosine2(M[0,:], M[1,:])\n",
    "\n",
    "# Compute the pairwise cosine similarity between the rows of your document-term matrix using the sklearn implementation. \n",
    "# Which document is the most similar to the first row according to cosine similarity? \n",
    "print(\"Most similar sentence to texts[0] according to cosine similarity\")\n",
    "S = sklearn.metrics.pairwise.cosine_similarity(M)\n",
    "j = S[0,:].argsort()[-2]\n",
    "print(texts[0])\n",
    "print(texts[j])\n",
    "\n",
    "# Based on the above experiment, suggest ways of modifying the word counts to make the cosine similarity more useful as a metric of text similarity. \n",
    "# Implement your idea and test it.\n",
    "print()\n",
    "print(\"Most similar sentence to texts[0] according to cosine similarity (remove stopwords)\")\n",
    "stopwords = ['a', 'and', 'the', 'is', 'in', 'on', 'at']\n",
    "texts = [ [ word for word in text if word not in stopwords] for text in texts ]\n",
    "vocab, M = word_count(texts)\n",
    "S = sklearn.metrics.pairwise.cosine_similarity(M)\n",
    "j = S[0,:].argsort()[-2]\n",
    "print(texts[0])\n",
    "print(texts[j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.5\n",
    "\n",
    "Scikit learn has a couple of classes which are useful for creating various versions of document-word matrices:\n",
    "- `sklearn.feature_extraction.text.CountVectorizer`\n",
    "- `sklearn.feature_extraction.text.TfidfVectorizer`\n",
    "\n",
    "Read the documentation of these classes and try to apply them on the [coco_val.txt](coco_val.tx) data. \n",
    "- Compute similarities/distances using a few versions of these document-word matrices and check how they compare to using plain word-counts as we have been doing so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word counts with CountVectorizer\n",
      "Number of features:  7213\n",
      "Character n-grams with CountVectorizer\n",
      "Number of features:  75257\n",
      "Similarities according to M1 vs M2\n",
      "a child holding a flowered umbrella and petting a yak\n",
      "0.535 0.689 a young man holding an umbrella next to a herd of cattle\n",
      "0.516 0.652 a young boy barefoot holding an umbrella touching the horn of a cow\n",
      "0.438 0.585 a young boy with an umbrella who is touching the horn of a cow\n",
      "0.395 0.661 a boy holding an umbrella while standing next to livestock\n",
      "0.333 0.538 a narrow kitchen filled with appliances and cooking utensils\n",
      "0.316 0.501 a galley kitchen with cabinets and appliances on both sides\n",
      "0.452 0.532 a hallway leading into a white kitchen with appliances\n",
      "0.468 0.517 doorway view of a kitchen with a sink stove refrigerator and pantry\n",
      "0.0 0.424 the pantry door of the small kitchen is closed\n",
      "0.606 0.597 a little girl holding a kitten next to a blue fence\n",
      "0.438 0.602 girl in a tank top holding a kitten in her back yard\n",
      "0.553 0.604 a young girl is holding a small cat\n",
      "0.528 0.61 girl with a yellow shirt holding a small cat\n",
      "0.452 0.479 a girl smiles as she holds a kitty cat\n",
      "0.562 0.502 a toilet sitting in a bathroom next to a sink\n",
      "0.452 0.512 a toilet in a bathroom with green faded paint\n",
      "0.412 0.52 a bathroom with a gouged wall and wall socket with no panel\n",
      "0.0 0.381 the toilet is near the door in the bathroom\n",
      "0.0833 0.508 the bathroom wall needs to be resurfaced and painted\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "doc = [ line.strip() for line in open('coco_val.txt')]\n",
    "\n",
    "print(\"Word counts with CountVectorizer\")\n",
    "cv = CountVectorizer(analyzer='word', lowercase=False, tokenizer=lambda x: x.split())\n",
    "M1 = cv.fit_transform(doc)\n",
    "print(\"Number of features: \", len(cv.get_feature_names()))\n",
    "\n",
    "print(\"Character n-grams with CountVectorizer\")\n",
    "cvng = CountVectorizer(analyzer='char', ngram_range=(1,5), lowercase=False)\n",
    "M2 = cvng.fit_transform(doc)\n",
    "print(\"Number of features: \", len(cvng.get_feature_names()))\n",
    "\n",
    "print(\"Similarities according to M1 vs M2\")\n",
    "print(doc[0])\n",
    "r11 = M1[0].toarray()\n",
    "r21 = M2[0].toarray()\n",
    "for i in range(1, 20):\n",
    "    r12 = M1[i].toarray()    \n",
    "    r22 = M2[i].toarray()\n",
    "    print(\"{:.3} {:.3} {}\".format(cosine2(r11, r12), cosine2(r21, r22), doc[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
